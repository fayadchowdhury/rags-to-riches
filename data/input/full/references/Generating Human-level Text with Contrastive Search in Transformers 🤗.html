<!doctype html>
<html class="">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" />
		<meta name="description" content="Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science." />
		<meta property="fb:app_id" content="1321688464574422" />
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@huggingface" />
		<meta name="twitter:image" content="https://huggingface.co/blog/assets/115_introducing_contrastive_search/thumbnail.png" />
		<meta property="og:title" content="Generating Human-level Text with Contrastive Search in Transformers ðŸ¤—" />
		<meta property="og:type" content="website" />
		<meta property="og:url" content="https://huggingface.co/blog/introducing-csearch" />
		<meta property="og:image" content="https://huggingface.co/blog/assets/115_introducing_contrastive_search/thumbnail.png" />

		<link rel="stylesheet" href="/front/build/kube-8e721ee/style.css" />

		<link rel="preconnect" href="https://fonts.gstatic.com" />
		<link
			href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,200;0,300;0,400;0,600;0,700;0,900;1,200;1,300;1,400;1,600;1,700;1,900&display=swap"
			rel="stylesheet"
		/>
		<link
			href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;600;700&display=swap"
			rel="stylesheet"
		/>

		<link
			rel="preload"
			href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css"
			as="style"
			onload="this.onload=null;this.rel='stylesheet'"
		/>
		<noscript>
			<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" />
		</noscript>

		<script>if (window.matchMedia('(prefers-color-scheme: dark)').matches) { document.documentElement.classList.add('dark'); }</script>
<link rel="canonical" href="https://huggingface.co/blog/introducing-csearch">
<link rel="alternate" hreflang="zh" href="https://huggingface.co/blog/zh/introducing-csearch">  <!-- HEAD_svelte-vwinwk_START --><link rel="alternate" type="application/rss+xml" href="/blog/feed.xml" title="Hugging Face Blog"><!-- HEAD_svelte-vwinwk_END -->

		<title>Generating Human-level Text with Contrastive Search in Transformers ðŸ¤—</title>

		<script
			defer
			data-domain="huggingface.co"
			event-loggedIn="true"
			src="/js/script.pageview-props.js"
		></script>
		<script>
			window.plausible =
				window.plausible ||
				function () {
					(window.plausible.q = window.plausible.q || []).push(arguments);
				};
		</script>
		<script>
			window.hubConfig = {"features":{"signupDisabled":false},"sshGitUrl":"git@hf.co","moonHttpUrl":"https:\/\/huggingface.co","captchaApiKey":"bd5f2066-93dc-4bdd-a64b-a24646ca3859","captchaDisabledOnSignup":false,"datasetViewerPublicUrl":"https:\/\/datasets-server.huggingface.co","stripePublicKey":"pk_live_x2tdjFXBCvXo2FFmMybezpeM00J6gPCAAc","environment":"production","userAgent":"HuggingFace (production)","spacesIframeDomain":"hf.space","spacesApiUrl":"https:\/\/api.hf.space","docSearchKey":"ece5e02e57300e17d152c08056145326e90c4bff3dd07d7d1ae40cf1c8d39cb6","logoDev":{"apiUrl":"https:\/\/img.logo.dev\/","apiKey":"pk_UHS2HZOeRnaSOdDp7jbd5w"}};
		</script>
		<script type="text/javascript" src="https://de5282c3ca0c.edge.sdk.awswaf.com/de5282c3ca0c/526cf06acb0d/challenge.js" defer></script>
	</head>
	<body class="flex flex-col min-h-dvh bg-white dark:bg-gray-950 text-black BlogPage">
		

<div class="flex min-h-dvh flex-col"><div class="SVELTE_HYDRATER contents" data-target="SystemThemeMonitor" data-props="{}"></div>
	<div class="SVELTE_HYDRATER contents" data-target="MainHeader" data-props="{&quot;authLight&quot;:{&quot;csrfToken&quot;:&quot;eyJkYXRhIjp7ImV4cGlyYXRpb24iOjE3MzMyNzA0Nzg2ODEsInVzZXJJZCI6IjY1NTQwMWJmNDMyYWYxYjExMTU3NDU4NSJ9LCJzaWduYXR1cmUiOiIzZmVhNDEwOGRlNmUwMWM5MjkwZDJiMDgyMDFmZGFlYTQzYmQ4ZTUxNjJiZGE1NmJkODQzNjgxZTRiZTE0NTExIn0=&quot;,&quot;hasHfLevelAccess&quot;:false,&quot;u&quot;:{&quot;avatarUrl&quot;:&quot;/avatars/60c9e476e92f24b4f1719e25c7563b73.svg&quot;,&quot;isPro&quot;:false,&quot;orgs&quot;:[],&quot;user&quot;:&quot;fayadchowdhury&quot;,&quot;canPost&quot;:false,&quot;canHaveBilling&quot;:true,&quot;canCreateOrg&quot;:true,&quot;theme&quot;:&quot;system&quot;,&quot;notifications&quot;:{},&quot;usage&quot;:{&quot;storage&quot;:{&quot;limit&quot;:500000000000,&quot;used&quot;:0,&quot;count&quot;:0},&quot;inferenceApi&quot;:{&quot;used&quot;:0,&quot;limit&quot;:1000,&quot;duration&quot;:86400,&quot;renewal&quot;:86400,&quot;lastUpdated&quot;:&quot;2024-12-03T00:00:55.093Z&quot;},&quot;zeroGpu&quot;:{&quot;base&quot;:300,&quot;current&quot;:300,&quot;lastUpdated&quot;:&quot;2024-12-03T00:00:55.093Z&quot;}}}},&quot;classNames&quot;:&quot;&quot;,&quot;avatarUrl&quot;:&quot;/avatars/60c9e476e92f24b4f1719e25c7563b73.svg&quot;,&quot;isWide&quot;:false,&quot;isZh&quot;:false,&quot;user&quot;:&quot;fayadchowdhury&quot;,&quot;unreadNotifications&quot;:0,&quot;csrf&quot;:&quot;eyJkYXRhIjp7ImV4cGlyYXRpb24iOjE3MzMyNzA0Nzg2ODEsInVzZXJJZCI6IjY1NTQwMWJmNDMyYWYxYjExMTU3NDU4NSJ9LCJzaWduYXR1cmUiOiIzZmVhNDEwOGRlNmUwMWM5MjkwZDJiMDgyMDFmZGFlYTQzYmQ4ZTUxNjJiZGE1NmJkODQzNjgxZTRiZTE0NTExIn0=&quot;,&quot;canCreateOrg&quot;:true,&quot;isPro&quot;:false}"><header class="border-b border-gray-100 "><div class="w-full px-4 container flex h-16 items-center"><div class="flex flex-1 items-center"><a class="mr-5 flex flex-none items-center lg:mr-6" href="/"><img alt="Hugging Face's logo" class="w-7 md:mr-2" src="/front/assets/huggingface_logo-noborder.svg">
				<span class="hidden whitespace-nowrap text-lg font-bold md:block">Hugging Face</span></a>
			<div class="relative flex-1 lg:max-w-sm mr-2 sm:mr-4 md:mr-3 xl:mr-6"><input autocomplete="off" class="w-full dark:bg-gray-950 pl-8 form-input-alt h-9 pr-3 focus:shadow-xl " name="" placeholder="Search models, datasets, users..."   spellcheck="false" type="text" value="">
	<svg class="absolute left-2.5 text-gray-400 top-1/2 transform -translate-y-1/2" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z" fill="currentColor"></path></svg>
	</div>
			<div class="flex flex-none items-center justify-center p-0.5 place-self-stretch lg:hidden"><button class="relative z-40 flex h-6 w-8 items-center justify-center" type="button"><svg width="1em" height="1em" viewBox="0 0 10 10" class="text-xl" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" preserveAspectRatio="xMidYMid meet" fill="currentColor"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z"></path></svg>
		</button>

	</div></div>
		<nav aria-label="Main" class="ml-auto hidden lg:block"><ul class="flex items-center space-x-1.5 2xl:space-x-2"><li class="hover:text-indigo-700"><a class="group flex items-center px-2 py-0.5 dark:hover:text-gray-400" href="/models"><svg class="mr-1.5 text-gray-400 group-hover:text-indigo-500" style="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path class="uim-quaternary" d="M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z" opacity=".25" fill="currentColor"></path><path class="uim-tertiary" d="M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z" opacity=".5" fill="currentColor"></path><path class="uim-primary" d="M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z" fill="currentColor"></path></svg>
					Models</a>
			</li><li class="hover:text-red-700"><a class="group flex items-center px-2 py-0.5 dark:hover:text-gray-400" href="/datasets"><svg class="mr-1.5 text-gray-400 group-hover:text-red-500" style="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 25 25"><ellipse cx="12.5" cy="5" fill="currentColor" fill-opacity="0.25" rx="7.5" ry="2"></ellipse><path d="M12.5 15C16.6421 15 20 14.1046 20 13V20C20 21.1046 16.6421 22 12.5 22C8.35786 22 5 21.1046 5 20V13C5 14.1046 8.35786 15 12.5 15Z" fill="currentColor" opacity="0.5"></path><path d="M12.5 7C16.6421 7 20 6.10457 20 5V11.5C20 12.6046 16.6421 13.5 12.5 13.5C8.35786 13.5 5 12.6046 5 11.5V5C5 6.10457 8.35786 7 12.5 7Z" fill="currentColor" opacity="0.5"></path><path d="M5.23628 12C5.08204 12.1598 5 12.8273 5 13C5 14.1046 8.35786 15 12.5 15C16.6421 15 20 14.1046 20 13C20 12.8273 19.918 12.1598 19.7637 12C18.9311 12.8626 15.9947 13.5 12.5 13.5C9.0053 13.5 6.06886 12.8626 5.23628 12Z" fill="currentColor"></path></svg>
					Datasets</a>
			</li><li class="hover:text-blue-700"><a class="group flex items-center px-2 py-0.5 dark:hover:text-gray-400" href="/spaces"><svg class="mr-1.5 text-gray-400 group-hover:text-blue-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 25 25"><path opacity=".5" d="M6.016 14.674v4.31h4.31v-4.31h-4.31ZM14.674 14.674v4.31h4.31v-4.31h-4.31ZM6.016 6.016v4.31h4.31v-4.31h-4.31Z" fill="currentColor"></path><path opacity=".75" fill-rule="evenodd" clip-rule="evenodd" d="M3 4.914C3 3.857 3.857 3 4.914 3h6.514c.884 0 1.628.6 1.848 1.414a5.171 5.171 0 0 1 7.31 7.31c.815.22 1.414.964 1.414 1.848v6.514A1.914 1.914 0 0 1 20.086 22H4.914A1.914 1.914 0 0 1 3 20.086V4.914Zm3.016 1.102v4.31h4.31v-4.31h-4.31Zm0 12.968v-4.31h4.31v4.31h-4.31Zm8.658 0v-4.31h4.31v4.31h-4.31Zm0-10.813a2.155 2.155 0 1 1 4.31 0 2.155 2.155 0 0 1-4.31 0Z" fill="currentColor"></path><path opacity=".25" d="M16.829 6.016a2.155 2.155 0 1 0 0 4.31 2.155 2.155 0 0 0 0-4.31Z" fill="currentColor"></path></svg>
					Spaces</a>
			</li><li class="hover:text-yellow-700 max-xl:hidden"><a class="group flex items-center px-2 py-0.5 dark:hover:text-gray-400" href="/posts"><svg class="mr-1.5 text-gray-400 group-hover:text-yellow-500 !text-yellow-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 12 12" preserveAspectRatio="xMidYMid meet"><path fill="currentColor" fill-rule="evenodd" d="M3.73 2.4A4.25 4.25 0 1 1 6 10.26H2.17l-.13-.02a.43.43 0 0 1-.3-.43l.01-.06a.43.43 0 0 1 .12-.22l.84-.84A4.26 4.26 0 0 1 3.73 2.4Z" clip-rule="evenodd"></path></svg>
					Posts</a>
			</li><li class="hover:text-yellow-700"><a class="group flex items-center px-2 py-0.5 dark:hover:text-gray-400" href="/docs"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="mr-1.5 text-gray-400 group-hover:text-yellow-500" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path opacity="0.5" d="M20.9022 5.10334L10.8012 10.8791L7.76318 9.11193C8.07741 8.56791 8.5256 8.11332 9.06512 7.7914L15.9336 3.73907C17.0868 3.08811 18.5002 3.26422 19.6534 3.91519L19.3859 3.73911C19.9253 4.06087 20.5879 4.56025 20.9022 5.10334Z" fill="currentColor"></path><path d="M10.7999 10.8792V28.5483C10.2136 28.5475 9.63494 28.4139 9.10745 28.1578C8.5429 27.8312 8.074 27.3621 7.74761 26.7975C7.42122 26.2327 7.24878 25.5923 7.24756 24.9402V10.9908C7.25062 10.3319 7.42358 9.68487 7.74973 9.1123L10.7999 10.8792Z" fill="currentColor" fill-opacity="0.75"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M21.3368 10.8499V6.918C21.3331 6.25959 21.16 5.61234 20.8346 5.03949L10.7971 10.8727L10.8046 10.874L21.3368 10.8499Z" fill="currentColor"></path><path opacity="0.5" d="M21.7937 10.8488L10.7825 10.8741V28.5486L21.7937 28.5234C23.3344 28.5234 24.5835 27.2743 24.5835 25.7335V13.6387C24.5835 12.0979 23.4365 11.1233 21.7937 10.8488Z" fill="currentColor"></path></svg>
					Docs</a>
			</li><li class="hover:text-green-700"><a class="group flex items-center px-2 py-0.5 dark:hover:text-gray-400" href="/enterprise"><svg class="mr-1.5 text-gray-400 group-hover:text-green-500" xmlns="http://www.w3.org/2000/svg" fill="none" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 33 27"><path fill="currentColor" fill-rule="evenodd" d="M13.5.7a8.7 8.7 0 0 0-7.7 5.7L1 20.6c-1 3.1.9 5.7 4.1 5.7h15c3.3 0 6.8-2.6 7.8-5.7l4.6-14.2c1-3.1-.8-5.7-4-5.7h-15Zm1.1 5.7L9.8 20.3h9.8l1-3.1h-5.8l.8-2.5h4.8l1.1-3h-4.8l.8-2.3H23l1-3h-9.5Z" clip-rule="evenodd"></path></svg>
					Enterprise</a>
			</li>

		<li><a class="group flex items-center px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400" href="/pricing">Pricing
			</a></li>

		<li><div class="relative group">
	<button class="px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-600 flex items-center " type="button">
		<svg class=" text-gray-500 w-5 group-hover:text-gray-400 dark:text-gray-300 dark:group-hover:text-gray-400" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 32 18" preserveAspectRatio="xMidYMid meet"><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 3.30221C14.4504 2.836 14.8284 2.45807 15.2946 2.45807H28.4933C28.9595 2.45807 29.3374 2.836 29.3374 3.30221C29.3374 3.76842 28.9595 4.14635 28.4933 4.14635H15.2946C14.8284 4.14635 14.4504 3.76842 14.4504 3.30221Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 9.00002C14.4504 8.53382 14.8284 8.15588 15.2946 8.15588H28.4933C28.9595 8.15588 29.3374 8.53382 29.3374 9.00002C29.3374 9.46623 28.9595 9.84417 28.4933 9.84417H15.2946C14.8284 9.84417 14.4504 9.46623 14.4504 9.00002Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 14.6978C14.4504 14.2316 14.8284 13.8537 15.2946 13.8537H28.4933C28.9595 13.8537 29.3374 14.2316 29.3374 14.6978C29.3374 15.164 28.9595 15.542 28.4933 15.542H15.2946C14.8284 15.542 14.4504 15.164 14.4504 14.6978Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M1.94549 6.87377C2.27514 6.54411 2.80962 6.54411 3.13928 6.87377L6.23458 9.96907L9.32988 6.87377C9.65954 6.54411 10.194 6.54411 10.5237 6.87377C10.8533 7.20343 10.8533 7.73791 10.5237 8.06756L6.23458 12.3567L1.94549 8.06756C1.61583 7.73791 1.61583 7.20343 1.94549 6.87377Z" fill="currentColor"></path></svg>
			
		</button>
	
	
	</div></li>
		<li><hr class="h-5 w-0.5 border-none bg-gray-100 dark:bg-gray-800"></li>
		<li><form action="/logout" method="POST" class="hidden"><input type="hidden" name="csrf" value="eyJkYXRhIjp7ImV4cGlyYXRpb24iOjE3MzMyNzA0Nzg2ODEsInVzZXJJZCI6IjY1NTQwMWJmNDMyYWYxYjExMTU3NDU4NSJ9LCJzaWduYXR1cmUiOiIzZmVhNDEwOGRlNmUwMWM5MjkwZDJiMDgyMDFmZGFlYTQzYmQ4ZTUxNjJiZGE1NmJkODQzNjgxZTRiZTE0NTExIn0="></form>
<div class="relative ml-2 w-[1.38rem] h-[1.38rem] ">
	<button class="ml-auto rounded-full ring-2 group ring-indigo-400 focus:ring-blue-500 hover:ring-offset-1 focus:ring-offset-1 focus:outline-none outline-none dark:ring-offset-gray-950 " type="button">
		
		<div class="relative"><img alt="" class="h-[1.38rem] w-[1.38rem] overflow-hidden rounded-full" src="/avatars/60c9e476e92f24b4f1719e25c7563b73.svg" crossorigin="anonymous">
			</div>
	
		</button>
	
	
	</div></li></ul></nav></div></header></div>
	
	<div class="bg-gradient-to-b py-3 text-sm md:text-base from-yellow-50 to-yellow-100 dark:from-yellow-500 dark:to-yellow-600 dark:text-gray-950 "><div class="container"><form class="flex flex-col justify-between md:flex-row md:items-center" action="/organizations/suggestions/dismiss" method="POST"><input type="hidden" name="csrf" value="eyJkYXRhIjp7ImV4cGlyYXRpb24iOjE3MzMyNzA0Nzg2ODEsInVzZXJJZCI6IjY1NTQwMWJmNDMyYWYxYjExMTU3NDU4NSJ9LCJzaWduYXR1cmUiOiIzZmVhNDEwOGRlNmUwMWM5MjkwZDJiMDgyMDFmZGFlYTQzYmQ4ZTUxNjJiZGE1NmJkODQzNjgxZTRiZTE0NTExIn0=">
				<div class="mb-2 md:mb-0">Hugging Face is way more fun with friends and colleagues! ðŸ¤—
					<a class="ml-2 underline" href="/organizations/suggestions">Join an organization </a></div>
				<button class="btn text-sm" type="submit">Dismiss this message</button></form></div></div>
	
	<div class="SVELTE_HYDRATER contents" data-target="SSOBanner" data-props="{&quot;organizations&quot;:[]}"></div>
	
	

	<main class="flex flex-1 flex-col"><div class="container relative flex flex-row justify-center gap-4"><div class="max-w-3xl pb-16 pt-6 max-lg:overflow-hidden lg:flex-1 lg:pt-16 2xl:max-w-4xl"><div class="blog-content copiable-code-container prose mx-auto lg:prose-lg 2xl:prose-lg prose-h1:mb-3 lg:px-8 [&_h1]:!mr-0"><div class="SVELTE_HYDRATER contents" data-target="RepoCodeCopy" data-props="{}"><div></div></div>
				<div class="mb-4"><a href="/blog" class="flex items-center font-sans !text-gray-500 !no-underline hover:!underline"><svg class="mr-2 h-3 w-3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M14 26l1.41-1.41L7.83 17H28v-2H7.83l7.58-7.59L14 6L4 16l10 10z" fill="currentColor"></path></svg>
						Back to Articles</a></div>

				<h1 class="group relative flex items-center"><!-- HTML_TAG_START -->
	<a 
		id="generating-human-level-text-with-contrastive-search-in-transformers-ðŸ¤—" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#generating-human-level-text-with-contrastive-search-in-transformers-ðŸ¤—"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Generating Human-level Text with Contrastive Search in Transformers ðŸ¤—
	</span>
<!-- HTML_TAG_END --></h1>
				<div><div class="mb-6 flex items-center gap-x-4 text-base">
		<span class="text-sm sm:text-base">Published
				November 8, 2022</span></div>
	<a target="_blank" class="btn mb-5 font-sans text-sm no-underline" href="https://github.com/huggingface/blog/blob/main/introducing-csearch.md">Update on GitHub</a></div>
				<div class="not-prose mb-6 lg:hidden"><div class="SVELTE_HYDRATER contents" data-target="UpvoteControl" data-props="{&quot;authLight&quot;:{&quot;csrfToken&quot;:&quot;eyJkYXRhIjp7ImV4cGlyYXRpb24iOjE3MzMyNzA0Nzg2ODEsInVzZXJJZCI6IjY1NTQwMWJmNDMyYWYxYjExMTU3NDU4NSJ9LCJzaWduYXR1cmUiOiIzZmVhNDEwOGRlNmUwMWM5MjkwZDJiMDgyMDFmZGFlYTQzYmQ4ZTUxNjJiZGE1NmJkODQzNjgxZTRiZTE0NTExIn0=&quot;,&quot;hasHfLevelAccess&quot;:false,&quot;u&quot;:{&quot;avatarUrl&quot;:&quot;/avatars/60c9e476e92f24b4f1719e25c7563b73.svg&quot;,&quot;isPro&quot;:false,&quot;orgs&quot;:[],&quot;user&quot;:&quot;fayadchowdhury&quot;,&quot;canPost&quot;:false,&quot;canHaveBilling&quot;:true,&quot;canCreateOrg&quot;:true,&quot;theme&quot;:&quot;system&quot;,&quot;notifications&quot;:{},&quot;usage&quot;:{&quot;storage&quot;:{&quot;limit&quot;:500000000000,&quot;used&quot;:0,&quot;count&quot;:0},&quot;inferenceApi&quot;:{&quot;used&quot;:0,&quot;limit&quot;:1000,&quot;duration&quot;:86400,&quot;renewal&quot;:86400,&quot;lastUpdated&quot;:&quot;2024-12-03T00:00:55.093Z&quot;},&quot;zeroGpu&quot;:{&quot;base&quot;:300,&quot;current&quot;:300,&quot;lastUpdated&quot;:&quot;2024-12-03T00:00:55.093Z&quot;}}}},&quot;maxShown&quot;:6,&quot;apiUrlPrefix&quot;:&quot;/api/blog/introducing-csearch&quot;,&quot;postLoginRedirectUrl&quot;:&quot;introducing-csearch&quot;,&quot;size&quot;:&quot;sm&quot;,&quot;style&quot;:&quot;horizontal&quot;,&quot;color&quot;:&quot;gray&quot;,&quot;upvotedColor&quot;:&quot;orange&quot;,&quot;upvoted&quot;:false,&quot;upvoters&quot;:[{&quot;_id&quot;:&quot;6032802e1f993496bc14d9e3&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/6032802e1f993496bc14d9e3/w6hr-DEQot4VVkoyRIBiy.png&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Omar Sanseviero&quot;,&quot;user&quot;:&quot;osanseviero&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;60638ffcc1b431dab68bf985&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1652289278612-60638ffcc1b431dab68bf985.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Rohola Zandie&quot;,&quot;user&quot;:&quot;Roh&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;60ff9a16d97410273ee4f3c4&quot;,&quot;avatarUrl&quot;:&quot;/avatars/15262cde59a2df265215575b8c97a867.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Manpreet Singh&quot;,&quot;user&quot;:&quot;singhmnprt01&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;618b40a1cabd3c4c8e448203&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/618b40a1cabd3c4c8e448203/Ccgv0dwgHEIb4vwYwHgQz.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Sambit Mukherjee&quot;,&quot;user&quot;:&quot;sadhaklal&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;62928e6556fedc76e3971e19&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/62928e6556fedc76e3971e19/Ye0xR859GTCs3ZTZSvlM3.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Ivan Sorokin&quot;,&quot;user&quot;:&quot;sorokin&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;62ff609559b9ff1ccb53228a&quot;,&quot;avatarUrl&quot;:&quot;/avatars/8e40cbf1a600b01e9b1ebc2f1704cb19.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Osama Khan&quot;,&quot;user&quot;:&quot;khanosama783&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;63ff00a512c51862e5d661d8&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/63ff00a512c51862e5d661d8/z4FmjxxEtEvvMTESqJv3L.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;yao&quot;,&quot;user&quot;:&quot;yaowenxu&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;64c3e7625e5bc55a92de44c7&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/urIJ05HhEJn0auwuA39c6.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Pedro Henrique Ton Pauletti&quot;,&quot;user&quot;:&quot;pedropauletti&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;64fdd75999123d7698d04d69&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/64fdd75999123d7698d04d69/1mfU8hchj-LShzzTtxAAK.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Kimleang Ly&quot;,&quot;user&quot;:&quot;kimleang123&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;65f61c4f133b39d44f331d88&quot;,&quot;avatarUrl&quot;:&quot;/avatars/cbef8f9192d219949f6201ebd38fa7af.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;ayoub elmendoub&quot;,&quot;user&quot;:&quot;showgun01&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;665369e6420092799deb865f&quot;,&quot;avatarUrl&quot;:&quot;/avatars/284bd5458f559e1036a7c68cd5f1c8e2.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;morror&quot;,&quot;user&quot;:&quot;hvgg1ngface&quot;,&quot;type&quot;:&quot;user&quot;}],&quot;upvotes&quot;:11}"><div class="flex flex-wrap items-center gap-2.5 pt-1 "><label class="shadow-alternate group flex h-9 cursor-pointer select-none items-center gap-2 rounded-lg border pl-3 pr-3.5 border-gray-300 bg-white dark:bg-gray-850"><input  type="checkbox"  class="peer hidden">
		<svg class="text-xs text-gray-500 peer-checked:text-gray-500 group-hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path fill="currentColor" d="M5.19 2.67a.94.94 0 0 1 1.62 0l3.31 5.72a.94.94 0 0 1-.82 1.4H2.7a.94.94 0 0 1-.82-1.4l3.31-5.7v-.02Z"></path></svg>
		Upvote

		<div class="font-semibold text-orange-500">11</div></label>


	<ul class="flex items-center  flex-row  text-base   "><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="osanseviero" style="content-visibility:auto;"><a href="/osanseviero" title="osanseviero"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/6032802e1f993496bc14d9e3/w6hr-DEQot4VVkoyRIBiy.png">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="Roh" style="content-visibility:auto;"><a href="/Roh" title="Roh"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1652289278612-60638ffcc1b431dab68bf985.jpeg">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="singhmnprt01" style="content-visibility:auto;"><a href="/singhmnprt01" title="singhmnprt01"><img class="overflow-hidden rounded-full" alt="" src="/avatars/15262cde59a2df265215575b8c97a867.svg">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="sadhaklal" style="content-visibility:auto;"><a href="/sadhaklal" title="sadhaklal"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/618b40a1cabd3c4c8e448203/Ccgv0dwgHEIb4vwYwHgQz.jpeg">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="sorokin" style="content-visibility:auto;"><a href="/sorokin" title="sorokin"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/62928e6556fedc76e3971e19/Ye0xR859GTCs3ZTZSvlM3.jpeg">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="khanosama783" style="content-visibility:auto;"><a href="/khanosama783" title="khanosama783"><img class="overflow-hidden rounded-full" alt="" src="/avatars/8e40cbf1a600b01e9b1ebc2f1704cb19.svg">
					</a>
			</li>

		<li class="text-gray-600 hover:text-gray-700 order-last ml-3"><button class="btn -ml-3 translate-x-px rounded-full border-2 border-white bg-gradient-to-br px-1.5 py-0.5 text-xs">+5</button></li></ul></div>



</div></div>
				<div class="not-prose"><div class="SVELTE_HYDRATER contents" data-target="BlogAuthorsByline" data-props="{&quot;authors&quot;:[{&quot;author&quot;:{&quot;_id&quot;:&quot;627ca439a09edfe62239c671&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1652335660508-noauth.jpeg&quot;,&quot;fullname&quot;:&quot;Tian Lan&quot;,&quot;name&quot;:&quot;GMFTBY&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isMod&quot;:false,&quot;followerCount&quot;:9}}],&quot;translators&quot;:[],&quot;proofreaders&quot;:[],&quot;lang&quot;:&quot;en&quot;,&quot;loggedInUser&quot;:&quot;fayadchowdhury&quot;}"><div class="not-prose"><div class="mb-12 flex flex-wrap items-center gap-x-5 gap-y-3.5">

<span class="inline-block "><span class="contents"><a href="/GMFTBY" class="flex items-center leading-tight"><img class="m-0 mr-2.5 size-9 !rounded-full sm:mr-3 sm:size-12" alt="Tian Lan's avatar" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1652335660508-noauth.jpeg">
					<div class="text-gray-900 dark:text-gray-300"><span class="block font-mono text-xs !leading-tight underline">GMFTBY</span>
						<span class="fullname font-sans font-semibold max-sm:text-sm">Tian Lan</span>
						<div class="flex items-center"></div>
					</div></a>
			</span>

	</span></div>
	</div></div></div>
				

				<!-- HTML_TAG_START -->
<hr>
<a target="_blank" href="https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/115_introducing_contrastive_search.ipynb">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

<h3 class="relative group flex items-center">
	<a 
		id="1-introduction" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#1-introduction"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		1. Introduction:
	</span>
</h3>
<p>

<div class="absolute -left-12 bottom-0 top-0 z-10 not-prose hidden lg:block"><div class="sticky top-4 flex"><div class="h-7 pt-[0.175rem]">
				<span class="peer" tabindex="0"><button class="select-none hover:cursor-pointer"><svg width="1em" height="1em" viewBox="0 0 10 10" class="text-lg opacity-80 hover:opacity-100" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" preserveAspectRatio="xMidYMid meet" fill="currentColor"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z"></path></svg></button></span>
				<div class="invisible w-0 -translate-x-24 -translate-y-6 overflow-hidden rounded-xl border bg-white transition-transform hover:visible hover:w-52 hover:translate-x-0 peer-focus-within:visible peer-focus-within:w-52 peer-focus-within:translate-x-0"><nav aria-label="Secondary" class="max-h-[550px] overflow-y-auto p-3"><ul><li class="mb-3 text-sm last:mb-0"><a class="mb-1 block break-words font-semibold text-gray-700 hover:underline active:text-gray-900 dark:active:text-gray-200 [&>*]:break-words" href="#reference" title="Reference:"><!-- HTML_TAG_START -->Reference:<!-- HTML_TAG_END --></a>
									<ul class="pl-1"></ul>
								</li><li class="mb-3 text-sm last:mb-0"><a class="mb-1 block break-words font-semibold text-gray-700 hover:underline active:text-gray-900 dark:active:text-gray-200 [&>*]:break-words" href="#acknowledgements" title="Acknowledgements:"><!-- HTML_TAG_START -->Acknowledgements:<!-- HTML_TAG_END --></a>
									<ul class="pl-1"></ul>
								</li></ul></nav></div></div></div></div>Natural language generation (i.e. text generation) is one of the core tasks in natural language processing (NLP). In this blog, we introduce the current state-of-the-art decoding method, <em><strong>Contrastive Search</strong></em>, for neural text generation. Contrastive search is originally proposed in <em>&quot;A Contrastive Framework for Neural Text Generation&quot;</em> <a href='#references'>[1]</a> (<a href="https://arxiv.org/abs/2202.06417">[Paper]</a><a href="https://github.com/yxuansu/SimCTG">[Official Implementation]</a>) at NeurIPS 2022. Moreover, in this follow-up work,  <em>&quot;Contrastive Search Is What You Need For Neural Text Generation&quot;</em> <a href='#references'>[2]</a> (<a href="https://arxiv.org/abs/2210.14140">[Paper]</a> <a href="https://github.com/yxuansu/Contrastive_Search_Is_What_You_Need">[Official Implementation]</a>), the authors further demonstrate that contrastive search can generate human-level text using <strong>off-the-shelf</strong> language models across <strong>16</strong> languages.</p>
<p><strong>[Remark]</strong> For users who are not familiar with text generation, please refer more details to <a href="https://huggingface.co/blog/how-to-generate">this blog post</a>.</p>
<hr>
<span id='demo'/>

<h3 class="relative group flex items-center">
	<a 
		id="2-hugging-face-ðŸ¤—-demo-of-contrastive-search" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#2-hugging-face-ðŸ¤—-demo-of-contrastive-search"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		2. Hugging Face ðŸ¤— Demo of Contrastive Search:
	</span>
</h3>
<p>Contrastive Search is now available on ðŸ¤— <code>transformers</code>, both on PyTorch and TensorFlow. You can interact with the examples shown in this blog post using your framework of choice in <a href="https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/115_introducing_contrastive_search.ipynb">this Colab notebook</a>, which is linked at the top. We have also built this awesome <a href="https://huggingface.co/spaces/joaogante/contrastive_search_generation">demo</a> which directly compares contrastive search with other popular decoding methods (e.g. beam search, top-k sampling <a href='#references'>[3]</a>, and nucleus sampling <a href='#references'>[4]</a>).</p>
<hr>
<span id='installation'/>

<h3 class="relative group flex items-center">
	<a 
		id="3-environment-installation" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#3-environment-installation"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		3. Environment Installation:
	</span>
</h3>
<p>Before running the experiments in the following sections, please install the update-to-date version of <code>transformers</code> as</p>
<pre><code class="language-yaml"><span class="hljs-string">pip</span> <span class="hljs-string">install</span> <span class="hljs-string">torch</span>
<span class="hljs-string">pip</span> <span class="hljs-string">install</span> <span class="hljs-string">&quot;transformers==4.24.0&quot;</span>
</code></pre>
<hr>
<span id='problems_of_decoding_methods'/>

<h3 class="relative group flex items-center">
	<a 
		id="4-problems-of-existing-decoding-methods" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#4-problems-of-existing-decoding-methods"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		4. Problems of Existing Decoding Methods:
	</span>
</h3>
<p>Decoding methods can be divided into two categories: (i) deterministic methods and (ii) stochastic methods. Let&#39;s discuss both!</p>
<span id='deterministic_methods'/>

<h4 class="relative group flex items-center">
	<a 
		id="41-deterministic-methods" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#41-deterministic-methods"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		4.1. Deterministic Methods:
	</span>
</h4>
<p>Deterministic methods, e.g. greedy search and beam search, generate text by selecting the text continuation with the highest likelihood measured by the language model. However, as widely discussed in previous studies <a href='#references'>[3]</a><a href='#references'>[4]</a>, deterministic methods often lead to the problem of <em>model degeneration</em>, i.e., the generated text is unnatural and contains undesirable repetitions.</p>
<p>Below, let&#39;s see an example of generated text from greedy search using GPT-2 model.</p>
<pre><code class="language-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, GPT2LMHeadModel

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;gpt2-large&#x27;</span>)
input_ids = tokenizer(<span class="hljs-string">&#x27;DeepMind Company is&#x27;</span>, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>).input_ids
model = GPT2LMHeadModel.from_pretrained(<span class="hljs-string">&#x27;gpt2-large&#x27;</span>)

output = model.generate(input_ids, max_length=<span class="hljs-number">128</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Output:\n&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
<span class="hljs-built_in">print</span>(tokenizer.decode(output[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>))
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
</code></pre>
<details open>
<summary><b>Model Output:</b></summary>

<pre><code>Output:
----------------------------------------------------------------------------------------------------
DeepMind Company is a leading AI research company, with a focus on deep learning and deep
learning-based systems.

The company&#39;s research is focused on the development of deep learning-based systems that
can learn from large amounts of data, and that can be used to solve real-world problems.

DeepMind&#39;s research is also used by the UK government to develop new technologies for the
UK&#39;s National Health Service.

DeepMind&#39;s research is also used by the UK government to develop new technologies for the
UK&#39;s National Health Service.

DeepMind&#39;s research is also used by the UK government to develop new technologies
----------------------------------------------------------------------------------------------------
</code></pre>
</details>

<p><strong>[Remark]</strong> From the result generated by greedy search, we can see obvious pattern of repetitions.</p>
<span id='stochastic_methods'/>

<h4 class="relative group flex items-center">
	<a 
		id="42-stochastic-methods" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#42-stochastic-methods"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		4.2. Stochastic Methods:
	</span>
</h4>
<p>To address the issues posed by deterministic methods, stochastic methods generate text by introducing randomness during the decoding process. Two widely-used stochastic methods are (i) top-k sampling <a href='#references'>[3]</a> and (ii) nucleus sampling (also called top-p sampling) <a href='#references'>[4]</a>.</p>
<p>Below, we illustrate an example of generated text by nucleus sampling (p=0.95) using the GPT-2 model.</p>
<pre><code class="language-python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, GPT2LMHeadModel

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;gpt2-large&#x27;</span>)
input_ids = tokenizer(<span class="hljs-string">&#x27;DeepMind Company is&#x27;</span>, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>).input_ids
model = GPT2LMHeadModel.from_pretrained(<span class="hljs-string">&#x27;gpt2-large&#x27;</span>)

torch.manual_seed(<span class="hljs-number">0.</span>)
output = model.generate(input_ids, do_sample=<span class="hljs-literal">True</span>, max_length=<span class="hljs-number">128</span>, top_p=<span class="hljs-number">0.95</span>, top_k=<span class="hljs-number">0</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Output:\n&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
<span class="hljs-built_in">print</span>(tokenizer.decode(output[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>))
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
</code></pre>
<details open>
<summary><b>Model Output:</b></summary>

<pre><code>Output:
----------------------------------------------------------------------------------------------------
DeepMind Company is a leading provider of AI-based research, development, and delivery of
AI solutions for security, infrastructure, machine learning, communications, and so on.&quot;

&#39;AI is not journalism&#39;

Worse still was the message its researchers hoped would reach the world&#39;s media â€” that it
was not really research, but rather a get-rich-quick scheme to profit from living forces&#39;
ignorance.

&quot;The thing is, we know that people don&#39;t consciously assess the value of the others&#39;
information. They understand they will get the same on their own.&quot;

One example? Given the details of today
----------------------------------------------------------------------------------------------------
</code></pre>
</details>

<p><strong>[Remark]</strong> While nucleus sampling can generate text free of repetitions, the semantic coherence of the generated text is not well-maintained. For instance, the generated phrase <em>&#39;AI is not journalism&#39;</em> is incoherent with respect to the given prefix, i.e. <em>&#39;DeepMind Company&#39;</em>.</p>
<p>We note that this semantic inconsistency problem can partially be remedied by lowering the temperature. However, reducing the temperature brings nucleus sampling closer to greedy search, which can be seen as a trade-off between greedy search and nucleus sampling. Generally, it is challenging to find a prompt and model-independent temperature that avoids both the pitfalls of greedy search and nucleus sampling.</p>
<hr>
<span id='contrastive_search'/>

<h3 class="relative group flex items-center">
	<a 
		id="5-contrastive-search" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#5-contrastive-search"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		5. Contrastive Search:
	</span>
</h3>
<p>In this section, we introduce a new decoding method, <em><strong>Contrastive Search</strong></em>, in details.</p>
<span id='contrastive_objective'/>

<h4 class="relative group flex items-center">
	<a 
		id="51-decoding-objective" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#51-decoding-objective"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		5.1. Decoding Objective:
	</span>
</h4>
<p>Given the prefix text <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{&lt; t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6079em;vertical-align:-0.1774em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span></span></span></span>, the selection of the output token <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> follows</p>
<center class="half">
    <img src="/blog/assets/115_introducing_contrastive_search/formulation.png" width="750"/>
</center>

<p>where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>V</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">V^{(k)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.888em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span> is the set of top-k predictions from the language model&#39;s probability distribution <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>Î¸</mi></msub><mo stretchy="false">(</mo><mi>v</mi><mi mathvariant="normal">âˆ£</mi><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_{\theta}(v|x_{&lt; t})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">Î¸</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord">âˆ£</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>. The first term, i.e. <em>model confidence</em>, is the probability of the candidate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span> predicted by the language model. The second term, <em>degeneration penalty</em>, measures how discriminative of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span> with respect to the previous context <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex"> x_{&lt; t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6079em;vertical-align:-0.1774em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span></span></span></span> and the function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo stretchy="false">(</mo><mo>â‹…</mo><mo separator="true">,</mo><mo>â‹…</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">s(\cdot, \cdot)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord">â‹…</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">â‹…</span><span class="mclose">)</span></span></span></span> computes the cosine similarity between the token representations. More specifically, the degeneration penalty is defined as the maximum cosine similarity between the token representation of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span>, i.e. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">h_{v}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, and that of all tokens in the context <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{&lt; t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6079em;vertical-align:-0.1774em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span></span></span></span>. Here, the candidate representation <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">h_{v}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is computed by the language model given the concatenation of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{&lt; t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6079em;vertical-align:-0.1774em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span>. Intuitively, a larger degeneration penalty of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span> means it is more similar (in the representation space) to the context, therefore more likely leading to the problem of model degeneration. The hyperparameter <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î±</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">Î±</span></span></span></span> regulates the importance of these two components. When <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î±</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\alpha=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">Î±</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span>, contrastive search degenerates to the vanilla greedy search.</p>
<p><strong>[Remark]</strong> When generating output, contrastive search jointly considers (i) the probability predicted by the language model to maintain the semantic coherence between the generated text and the prefix text; and (ii) the similarity with respect to the previous context to avoid model degeneration.</p>
<span id='contrastive_generation'/>

<h4 class="relative group flex items-center">
	<a 
		id="52-generating-text-with-contrastive-search" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#52-generating-text-with-contrastive-search"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		5.2. Generating Text with Contrastive Search:
	</span>
</h4>
<p>Below, we use the same prefix text (i.e. <em>&quot;DeepMind Company is&quot;</em>) as in Section <a href='#deterministic_methods'>4.1</a> and <a href='#stochastic_methods'>4.2</a>, and generate the text with contrastive search (k=4 and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î±</mi><mo>=</mo><mn>0.6</mn></mrow><annotation encoding="application/x-tex">\alpha=0.6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">Î±</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.6</span></span></span></span>). To fully demonstrate the superior capability of contrastive search, we let the language model generate a <strong>long</strong> document with <strong>512</strong> tokens as</p>
<pre><code class="language-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> GPT2Tokenizer, GPT2LMHeadModel

model_name = <span class="hljs-string">&#x27;gpt2-large&#x27;</span>
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name, pad_token_id=tokenizer.eos_token_id)
model.<span class="hljs-built_in">eval</span>()

<span class="hljs-comment"># prepare the prefix</span>
prefix_text = <span class="hljs-string">r&#x27;DeepMind Company is&#x27;</span>
input_ids = tokenizer(prefix_text, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>).input_ids

<span class="hljs-comment"># generate the result with contrastive search</span>
output = model.generate(input_ids, penalty_alpha=<span class="hljs-number">0.6</span>, top_k=<span class="hljs-number">4</span>, max_length=<span class="hljs-number">512</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Output:\n&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
<span class="hljs-built_in">print</span>(tokenizer.decode(output[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>))
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
</code></pre>
<p>The arguments are as follows:</p>
<ul>
<li><code>--top_k</code>: The hyperparameter <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> in contrastive search.</li>
<li><code>--penalty_alpha</code>: The hyperparameter <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î±</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">Î±</span></span></span></span> in contrastive search.</li>
</ul>
<details open>
<summary><b>Model Output:</b></summary>

<pre><code>Output:
----------------------------------------------------------------------------------------------------
DeepMind Company is a leader in artificial intelligence (AI). We have a long history of working
with companies such as Google, Facebook, Amazon, and Microsoft to build products that improve
people&#39;s lives, and today we are excited to announce that DeepMind&#39;s AlphaGo program has won the
game of Go, becoming the first program to defeat a professional Go player.

The victory is a testament to the power of deep learning, and to the incredible work of our
research team, which has been at the forefront of AI research for the past five years. AlphaGo
is one of the most advanced Go programs ever created, and its performance is an important step
towards the goal of human-level AI.

&quot;This is the culmination of a decade of hard work,&quot; said Andy Ng, co-founder and CTO of DeepMind.
&quot;We are thrilled to have achieved this milestone and look forward to continuing to develop AI that
can be used in a wide range of applications and to help people live better lives.&quot;

DeepMind&#39;s work on Go began in 2010, when it began to train a neural network to play Go using
millions of games played by top Go players around the world. Since then, the team has refined the
algorithm, adding more and more layers of reinforcement learning to make it better at recognizing
patterns and making decisions based on those patterns. In the past year and a half, the team has
made significant progress in the game, winning a record-tying 13 games in a row to move into the
top four of the world rankings.

&quot;The game of Go is a complex game in which players have to be very careful not to overextend their
territory, and this is something that we have been able to improve over and over again,&quot; said
Dr. Demis Hassabis, co-founder and Chief Scientific Officer of DeepMind. &quot;We are very proud of our
team&#39;s work, and we hope that it will inspire others to take the next step in their research and
apply the same techniques to other problems.&quot;

In addition to the win in Go, DeepMind has also developed an AI system that can learn to play a
number of different games, including poker, Go, and chess. This AI system, called Tarsier, was
developed in partnership with Carnegie Mellon University and the University of California,
Berkeley, and is being used to teach computer vision and machine learning to identify objects in
images and recognize speech in natural language. Tarsier has been trained to play the game of Go
and other games on a
----------------------------------------------------------------------------------------------------
</code></pre>
</details>

<p><strong>[Remark]</strong> We see that the generated text is of exceptionally high quality. The entire document is grammatically fluent as well as semantically coherent. Meanwhile, the generated text also well maintains its factually correctness. For instance, in the first paragraph, it elaborates <em>&quot;AlphaGo&quot;</em> as the <em>&quot;first program to defeat a professional Go player&quot;</em>.</p>
<span id='contrastive_visual_demonstration'/>

<h4 class="relative group flex items-center">
	<a 
		id="53-visual-demonstration-of-contrastive-search" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#53-visual-demonstration-of-contrastive-search"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		5.3. Visual Demonstration of Contrastive Search:
	</span>
</h4>
<p>To better understand how contrastive search works, we provide a visual comparison between greedy search (<a href='#deterministic_methods'>Section 4.1</a>) and contrastive search. Specifically, we visualize the token similarity matrix of the generated text from greedy search and contrastive search, respectively. The similarity between two tokens is defined as the cosine similarity between their token representations (i.e. the hidden states of the last transformer layer). The results of greedy search (top) and contrastive search (bottom) are shown in the Figure below.</p>
<center class="half">
    <img src="/blog/assets/115_introducing_contrastive_search/greedy_search_visualization.png" width="400"/>
    <img src="/blog/assets/115_introducing_contrastive_search/contrastive_search_visualization.png" width="400"/>
</center>

<p><strong>[Remark]</strong> From the result of greedy search, we see high similarity scores in the off-diagonal entries which clearly indicates the generated repetitions by greedy search. On the contrary, in the result of contrastive search, the high similarity scores mostly appear in the diagonal entries which verifies that the degeneration problem is successfully addressed. This nice property of contrastive search is achieved by the introduction of degeneration penalty (see <a href='#contrastive_objective'>Section 5.1</a>) during the decoding process.</p>
<hr>
<span id='more_examples'/>

<h3 class="relative group flex items-center">
	<a 
		id="6-more-generated-examples" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#6-more-generated-examples"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		6. More Generated Examples:
	</span>
</h3>
<p>In this section, we provide more generated examples to compare different decoding methods.</p>
<span id='gpt2_example_one'/>

<h4 class="relative group flex items-center">
	<a 
		id="61-example-one---gpt-2" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#61-example-one---gpt-2"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		6.1. Example One - GPT-2:
	</span>
</h4>
<p>In this part, we use GPT-2 to generate text with the prefix text from the original <a href="https://openai.com/blog/better-language-models/">OpenAI blog</a> that announced the release of GPT-2.</p>
<blockquote>
<p><em>In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.</em></p>
</blockquote>
<details open>
<summary><b> Load the language model and prepare the prefix text:</b></summary>

<pre><code class="language-python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, GPT2LMHeadModel

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;gpt2-large&#x27;</span>)
model = GPT2LMHeadModel.from_pretrained(<span class="hljs-string">&#x27;gpt2-large&#x27;</span>)

prefix_text = <span class="hljs-string">r&quot;In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.&quot;</span>
input_ids = tokenizer(prefix_text, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>).input_ids
</code></pre>
</details>

<span id='gpt2_greedy_example_one'/>

<h5 class="relative group flex items-center">
	<a 
		id="611-generating-text-with-greedy-search" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#611-generating-text-with-greedy-search"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		6.1.1. Generating Text with Greedy Search:
	</span>
</h5>
<details>
<summary><b>Code: [click to expand]</b></summary>

<pre><code class="language-python">output = model.generate(input_ids, max_length=<span class="hljs-number">512</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Output:\n&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
<span class="hljs-built_in">print</span>(tokenizer.decode(output[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>))
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
</code></pre>
</details>

<details>
<summary><b>Model Output: [click to expand]</b></summary>

<pre><code>Output:
----------------------------------------------------------------------------------------------------
In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously
unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact
that the unicorns spoke perfect English.

The researchers, led by Dr. David R. Williams of the University of California, Santa Cruz,
discovered the unicorns in the Andes Mountains of Peru. The area is known for its unique geology
and is home to a number of rare species of animals.

The researchers found the unicorns in the Andes Mountains of Peru.

&quot;We were surprised to find that the unicorns were able to communicate with each other,&quot; Williams
said. &quot;We were also surprised to find that they were able to communicate in English.&quot;

The researchers believe that the unicorns are descendants of the ancient Incas, who lived in the
area around 2,000 years ago.

&quot;The Incas were the first people to use the Andes Mountains as a refuge from the harsh climate of
the Andes,&quot; Williams said. &quot;They were also the first people to use the Andes Mountains as a place
to hunt and gather food.&quot;

The researchers believe that the unicorns are descendants of the ancient Incas, who lived in the
area around 2,000 years ago.

&quot;The Incas were the first people to use the Andes Mountains as a refuge from the harsh climate of
the Andes,&quot; Williams said. &quot;They were also the first people to use the Andes Mountains as a place
to hunt and gather food.&quot;

The researchers believe that the unicorns are descendants of the ancient Incas, who lived in the
area around 2,000 years ago.

&quot;The Incas were the first people to use the Andes Mountains as a refuge from the harsh climate of
the Andes,&quot; Williams said. &quot;They were also the first people to use the Andes Mountains as a place
to hunt and gather food.&quot;

The researchers believe that the unicorns are descendants of the ancient Incas, who lived in the
area around 2,000 years ago.

&quot;The Incas were the first people to use the Andes Mountains as a refuge from the harsh climate of
the Andes,&quot; Williams said. &quot;They were also the first people to use the Andes Mountains as a place
to hunt and gather food.&quot;

The researchers believe that the unicorns are descendants of the ancient Incas, who lived in the
area around 2,000 years ago
----------------------------------------------------------------------------------------------------
</code></pre>
</details>

<span id='gpt2_nucleus_example_one'/>

<h5 class="relative group flex items-center">
	<a 
		id="612-generating-text-with-nucleus-sampling" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#612-generating-text-with-nucleus-sampling"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		6.1.2. Generating Text with Nucleus Sampling:
	</span>
</h5>
<details>
<summary><b>Code: [click to expand]</b></summary>

<pre><code class="language-python">torch.manual_seed(<span class="hljs-number">0.</span>)
output = model.generate(input_ids, do_sample=<span class="hljs-literal">True</span>, max_length=<span class="hljs-number">512</span>, top_p=<span class="hljs-number">0.95</span>, top_k=<span class="hljs-number">0</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Output:\n&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
<span class="hljs-built_in">print</span>(tokenizer.decode(output[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>))
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
</code></pre>
</details>


<details>
<summary><b>Model Output: [click to expand]</b></summary>

<pre><code>Output:
----------------------------------------------------------------------------------------------------
In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously
unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact
that the unicorns spoke perfect English. The study was published in the Journal of Zoology in
March 2016.

Polygynous mammals such as unicorns have remained largely unknown to science. Professor Gustavo
Giacota, from the University of Oxford who led the study, said that they had been documented as
far as Eastern Siberia in Russia, but had only been seen a handful of times in the Gobi Desert.

Tiny animals with pale and shiny coats live in the presence of human beings and are hardly likely
to be victims of any cruelty. However, there is some evidence of the condition occurring in both
humans and animals in remote regions, which might have similarities to &quot;black moles&quot; that coexist
on the skin.

It is thought that Unicorns could be inside themselves, that they have different scents depending
on their current environment, or just fall out and there are plenty of legends of how they have
survived. Experts speculate that the moths and other animals could be remnants of the Yezidi Isis
and Charon, which literally is both the word which means great bird, and the Greek word for sound.
It is said that the Isis and Charon taught their young the use of voice in the form of calling out
to others.

The scientists think that it could be ancient folklore that has survived and is no longer attributed
to a real entity
----------------------------------------------------------------------------------------------------
</code></pre>
</details>


<span id='gpt2_contrastive_example_one'/>

<h5 class="relative group flex items-center">
	<a 
		id="613-generating-text-with-contrastive-search" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#613-generating-text-with-contrastive-search"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		6.1.3. Generating Text with Contrastive Search:
	</span>
</h5>
<details open>
<summary><b>Code:</b></summary>

<pre><code class="language-python">output = model.generate(input_ids, max_length=<span class="hljs-number">512</span>, penalty_alpha=<span class="hljs-number">0.6</span>, top_k=<span class="hljs-number">4</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Output:\n&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
<span class="hljs-built_in">print</span>(tokenizer.decode(output[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>))
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
</code></pre>
</details>

<details open>
<summary><b>Model Output:</b></summary>

<pre><code>Output:
----------------------------------------------------------------------------------------------------
In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored
valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns
spoke perfect English.

According to the BBC, a team of scientists led by Dr David MacKay, from the University of Bristol, spent
two years searching for the unicorn herd, which they discovered during a survey of the area.

&quot;It&#39;s a very rare find,&quot; MacKay told the BBC. &quot;There are a few in the Himalayas, but this is the first
time we&#39;ve been able to find one in such a remote area.&quot;

The team was surprised to find a herd of unicorns living in a region that has been known to be a hotbed
of poaching, with many of the animals poached for their horns, which are used in traditional Chinese
medicine to treat everything from rheumatism to cancer.

&quot;We knew that the area was rich in rhino horn, but we had no idea how many there were, or what they were
doing there,&quot; MacKay said. &quot;This is an area of high poaching pressure, and we wanted to find out what was
going on.&quot;

In order to do so, the team used GPS collars to track the animals as they moved around the mountain and
the surrounding area. The GPS data was then compared with information gathered from local villagers, who
had a wealth of information about the animals&#39; movements, including where they were eating, what they were
doing at night, and how much time they spent in the mountains each day.

After analyzing the data, the team determined that the herd consisted of at least three species of unicorns,
including a male and two females. One of the females was the mother of the male, and the other two were her
daughters. All three had the same horn color, which is believed to be a sign of purity in the animal kingdom.

While the discovery is exciting, it&#39;s not the first time scientists have discovered an animal that speaks
English. Last year, scientists discovered a species of porcupine that can be heard by humans, and has been
dubbed &quot;Porcupine Man&quot; for his ability to converse with the human race.
----------------------------------------------------------------------------------------------------
</code></pre>
</details>


<span id='opt_example_two'/>

<h4 class="relative group flex items-center">
	<a 
		id="62-example-two---opt" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#62-example-two---opt"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		6.2. Example Two - OPT:
	</span>
</h4>
<p>In this part, we use the OPT model <a href='#references'>[5]</a> which is recently released by Meta to generate text by taking the first two sentences from the abstract of the prestigious ResNet paper <a href='#references'>[6]</a>.</p>
<blockquote>
<p>Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously.</p>
</blockquote>
<details open>
<summary><b> Load the language model and prepare the prefix text:</b></summary>

<pre><code class="language-python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, OPTForCausalLM
model_name = <span class="hljs-string">r&#x27;facebook/opt-1.3b&#x27;</span>
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = OPTForCausalLM.from_pretrained(model_name)

prefix_text = <span class="hljs-string">r&quot;Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously.&quot;</span>
input_ids = tokenizer(prefix_text, return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>).input_ids
</code></pre>
</details>



<span id='opt_greedy_example_two'/>

<h5 class="relative group flex items-center">
	<a 
		id="621-generating-text-with-greedy-search" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#621-generating-text-with-greedy-search"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		6.2.1. Generating Text with Greedy Search:
	</span>
</h5>
<details>
<summary><b>Code: [click to expand]</b></summary>

<pre><code class="language-python">output = model.generate(input_ids, max_length=<span class="hljs-number">256</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Output:\n&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
<span class="hljs-built_in">print</span>(tokenizer.decode(output[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>))
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
</code></pre>
</details>

<details>
<summary><b>Model Output: [click to expand]</b></summary>

<pre><code>Output:
----------------------------------------------------------------------------------------------------
Deeper neural networks are more difficult to train. We present a residual learning framework to ease
the training of networks that are substantially deeper than those used previously. We show that the
residual learning framework can be used to train deep neural networks that are significantly more
difficult to train than those used previously. We also show that the residual learning framework can
be used to train deep neural networks that are significantly more difficult to train than those used
previously.

The paper presents a new residual learning framework for deep neural networks that is based on the
concept of residuals. The residuals are the residuals of the network that are not used in the training
process. The residuals are computed by taking the residuals of the network that are used in the training
process and subtracting the residuals of the network that are not used in the training process. The
residuals are then used to train the network. The residuals are computed by taking the residuals of
the network that are used in the training process and subtracting the residuals of the network that
are not used in the training process. The residuals are then used to train the network. The residuals
are computed by taking the residuals of the network that are used in the training process and
subtracting the residuals of the
----------------------------------------------------------------------------------------------------
</code></pre>
</details>


<span id='opt_greedy_example_two'/>

<h5 class="relative group flex items-center">
	<a 
		id="622-generating-text-with-nucleus-sampling" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#622-generating-text-with-nucleus-sampling"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		6.2.2. Generating Text with Nucleus Sampling:
	</span>
</h5>
<details>
<summary><b>Code: [click to expand]</b></summary>

<pre><code class="language-python">torch.manual_seed(<span class="hljs-number">0.</span>)
output = model.generate(input_ids, do_sample=<span class="hljs-literal">True</span>, max_length=<span class="hljs-number">256</span>, top_p=<span class="hljs-number">0.95</span>, top_k=<span class="hljs-number">0</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Output:\n&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
<span class="hljs-built_in">print</span>(tokenizer.decode(output[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>))
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
</code></pre>
</details>


<details>
<summary><b>Model Output: [click to expand]</b></summary>

<pre><code>Output:
----------------------------------------------------------------------------------------------------
Deeper neural networks are more difficult to train. We present a residual learning framework to ease the
training of networks that are substantially deeper than those used previously. The theory focuses on
several aspects of learning, including the dynamics of replicative and non-replicative aspects of learning.
This framework emphasizes learning by entropy. New randomized algorithms enable training networks with
residual learning, so that deep networks can be deployed as reliably and as efficiently as their more
conventional counterparts.
----------------------------------------------------------------------------------------------------
</code></pre>
</details>



<span id='opt_contrastive_example_two'/>

<h5 class="relative group flex items-center">
	<a 
		id="623-generating-text-with-contrastive-search" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#623-generating-text-with-contrastive-search"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		6.2.3. Generating Text with Contrastive Search:
	</span>
</h5>
<details open>
<summary><b>Code:</b></summary>

<pre><code class="language-python">output = model.generate(input_ids, max_length=<span class="hljs-number">256</span>, penalty_alpha=<span class="hljs-number">0.6</span>, top_k=<span class="hljs-number">6</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Output:\n&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
<span class="hljs-built_in">print</span>(tokenizer.decode(output[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>))
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&quot;</span> + <span class="hljs-number">100</span> * <span class="hljs-string">&#x27;-&#x27;</span>)
</code></pre>
</details>

<details open>
<summary><b>Model Output:</b></summary>

<pre><code>Output:
----------------------------------------------------------------------------------------------------
Deeper neural networks are more difficult to train. We present a residual learning framework to ease
the training of networks that are substantially deeper than those used previously.

In this paper, we propose a model-based residual learning (MBRL) framework that is based on neural
networks trained on data that is sparse in terms of dimensionality (e.g., 1, 2, 3, etc.). The network
parameters are chosen such that there is a high probability of convergence, i.e., the number of
iterations is large enough to minimize the variance of the residuals. This is achieved by training
the network on a set of training data, in which the data is sparse in terms of dimensionality, and
then discarding the nonparametric part of the data after training is complete.

We show that MBRL outperforms other methods for deep reinforcement learning (RL) and deep convolutional
neural networks (CNNs) by a factor of at least 2. In addition, we show that, compared to CNNs, MBRL
performs better in two-dimensional (2D) and three-dimensional (3D) cases.
----------------------------------------------------------------------------------------------------
</code></pre>
</details>

<hr>
<span id='resources'/>

<h3 class="relative group flex items-center">
	<a 
		id="7-resources" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#7-resources"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		7. Resources:
	</span>
</h3>
<p>For more details of contrastive search, please check our papers and code as</p>
<ul>
<li><strong>A Contrastive Framework for Neural Text Generation</strong>: (1) <a href="https://arxiv.org/abs/2202.06417">Paper</a> and (2) <a href="https://github.com/yxuansu/SimCTG">Official Implementation</a>.</li>
<li><strong>Contrastive Search Is What You Need For Neural Text Generation</strong>: (1) <a href="https://arxiv.org/abs/2210.14140">Paper</a> and (2) <a href="https://github.com/yxuansu/Contrastive_Search_Is_What_You_Need">Official Implementation</a>.</li>
</ul>
<hr>
<span id='citation'/>

<h3 class="relative group flex items-center">
	<a 
		id="8-citation" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#8-citation"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		8. Citation:
	</span>
</h3>
<pre><code class="language-bibtex">@inproceedings{su2022a,
   title={A Contrastive Framework for Neural Text Generation},
   author={Yixuan Su and Tian Lan and Yan Wang and Dani Yogatama and Lingpeng Kong and Nigel Collier},
   booktitle={Advances in Neural Information Processing Systems},
   editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
   year={2022},
   url={https://openreview.net/forum?id=V88BafmH9Pj}
}

@article{su2022contrastiveiswhatyouneed,
  title={Contrastive Search Is What You Need For Neural Text Generation},
  author={Su, Yixuan and Collier, Nigel},
  journal={arXiv preprint arXiv:2210.14140},
  year={2022}
}
</code></pre>
<hr>
<span id='references'/>

<h2 class="relative group flex items-center">
	<a 
		id="reference" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#reference"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Reference:
	</span>
</h2>
<blockquote>
<p>[1] Su et al., 2022 <a href="https://arxiv.org/abs/2202.06417">&quot;A Contrastive Framework for Neural Text Generation&quot;</a>, NeurIPS 2022</p>
</blockquote>
<blockquote>
<p>[2] Su and Collier, 2022 <a href="https://arxiv.org/abs/2210.14140">&quot;Contrastive Search Is What You Need For Neural Text Generation&quot;</a>, Arxiv 2022</p>
</blockquote>
<blockquote>
<p>[3] Fan et al., 2018 <a href="https://arxiv.org/abs/1805.04833">&quot;Hierarchical Neural Story Generation&quot;</a>, ACL 2018</p>
</blockquote>
<blockquote>
<p>[4] Holtzman et al., 2020 <a href="https://arxiv.org/abs/1904.09751">&quot;The Curious Case of Neural Text Degeneration&quot;</a>, ICLR 2020</p>
</blockquote>
<blockquote>
<p>[5] Zhang et al., 2022 <a href="https://arxiv.org/abs/2205.01068">&quot;OPT: Open Pre-trained Transformer Language Models&quot;</a>, Arxiv 2022</p>
</blockquote>
<blockquote>
<p>[6] He et al., 2016 <a href="https://arxiv.org/abs/1512.03385">&quot;Deep Residual Learning for Image Recognition&quot;</a>, CVPR 2016</p>
</blockquote>
<hr>
<p><em>- Written by Yixuan Su and Tian Lan</em></p>
<hr>
<span id='acknowledgements'/>


<h2 class="relative group flex items-center">
	<a 
		id="acknowledgements" 
		class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" 
		href="#acknowledgements"
	>
		<span class="header-link"><svg class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span>
	</a>
	<span>
		Acknowledgements:
	</span>
</h2>
<p>We would like to thank Joao Gante (<a href="https://huggingface.co/joaogante">@joaogante</a>), Patrick von Platen (<a href="https://huggingface.co/patrickvonplaten">@patrickvonplaten</a>), and Sylvain Gugger (<a href="https://github.com/sgugger">@sgugger</a>) for their help and guidance in adding contrastive search mentioned in this blog post into the <code>transformers</code> library.</p>
<!-- HTML_TAG_END --></div>
			<div class="mx-auto max-w-5xl border-t border-gray-200 py-16"><div class="container grid gap-4 py-8"><div class="grid gap-6 md:grid-cols-2"><p class="col-span-1 mb-6 text-center text-lg font-semibold md:col-span-2">More Articles from our Blog</p>
							<div class="SVELTE_HYDRATER contents" data-target="BlogThumbnail" data-props="{&quot;blog&quot;:{&quot;authors&quot;:[{&quot;user&quot;:&quot;andito&quot;},{&quot;user&quot;:&quot;merve&quot;},{&quot;user&quot;:&quot;mfarre&quot;},{&quot;user&quot;:&quot;eliebak&quot;},{&quot;user&quot;:&quot;pcuenq&quot;}],&quot;canonical&quot;:true,&quot;isUpvotedByUser&quot;:false,&quot;publishedAt&quot;:&quot;2024-11-26T00:00:00.000Z&quot;,&quot;slug&quot;:&quot;smolvlm&quot;,&quot;title&quot;:&quot;SmolVLM - small yet mighty Vision Language Model&quot;,&quot;upvotes&quot;:102,&quot;thumbnail&quot;:&quot;/blog/assets/smolvlm/banner.png&quot;},&quot;blogUrl&quot;:&quot;/blog&quot;,&quot;lang&quot;:&quot;en&quot;,&quot;loggedInUser&quot;:&quot;fayadchowdhury&quot;}"><a class="flex lg:col-span-1 hover:shadow-alternate group relative flex-col overflow-hidden rounded-xl border border-gray-100 shadow-sm transition-shadow" href="/blog/smolvlm"><div class="aspect-[1.91/1] w-full rounded-b shadow-alternate relative flex-none overflow-hidden rounded-lg bg-white"><div class="absolute inset-0 group-hover:opacity-40 dark:backdrop-brightness-105"></div>

		<img src="/blog/assets/smolvlm/banner.png" class="h-full w-full object-cover group-hover:brightness-110" alt=""></div>

	<div class="flex flex-col p-4"><h2 class="font-serif font-semibold group-hover:underline text-xl">SmolVLM - small yet mighty Vision Language Model</h2>

		<p class="mt-3 flex flex-wrap items-center gap-y-1.5 font-mono text-xs text-gray-500">
				ByÂ <object title="">

<span class="inline-block "><span class="contents"><a href="/andito" class="hover:underline">andito</a></span>

	</span></object>
				<span class="mx-2 h-1 w-1 flex-none bg-gray-200"></span>
			<span>November 26, 2024</span>
			
			<span class="px-1.5 text-gray-300">â€¢</span>

				<svg class="flex-none w-3 mr-1 text-gray-400" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12" fill="transparent"><path d="M9.30013 9.29152H9.3H2.7H2.69987C2.62308 9.29154 2.54762 9.27146 2.481 9.23328C2.41437 9.1951 2.3589 9.14015 2.32009 9.07389C2.28128 9.00763 2.26048 8.93237 2.25977 8.85558C2.25907 8.7798 2.27796 8.70513 2.31458 8.63882L5.62238 2.9426L5.67518 2.85168C5.7059 2.81806 5.74178 2.78928 5.78164 2.76649C5.84813 2.72848 5.9234 2.70848 6 2.70848C6.0766 2.70848 6.15187 2.72848 6.21836 2.76649C6.28441 2.80425 6.33953 2.85848 6.37836 2.92389L9.68527 8.63855C9.72199 8.70493 9.74093 8.7797 9.74023 8.85558C9.73952 8.93237 9.71872 9.00763 9.67991 9.07389C9.6411 9.14015 9.58563 9.1951 9.519 9.23328C9.45238 9.27146 9.37692 9.29154 9.30013 9.29152Z" stroke="currentColor"></path></svg>

				102</p></div></a></div><div class="SVELTE_HYDRATER contents" data-target="BlogThumbnail" data-props="{&quot;blog&quot;:{&quot;authors&quot;:[{&quot;user&quot;:&quot;xuanricheng&quot;,&quot;guest&quot;:true,&quot;org&quot;:&quot;BAAI&quot;},{&quot;user&quot;:&quot;lilaczheng&quot;,&quot;guest&quot;:true,&quot;org&quot;:&quot;BAAI&quot;},{&quot;user&quot;:&quot;xiyang99&quot;,&quot;guest&quot;:true,&quot;org&quot;:&quot;BAAI&quot;},{&quot;user&quot;:&quot;Yonghua&quot;,&quot;guest&quot;:true,&quot;org&quot;:&quot;BAAI&quot;},{&quot;user&quot;:&quot;philokey&quot;,&quot;guest&quot;:true,&quot;org&quot;:&quot;BAAI&quot;},{&quot;user&quot;:&quot;xuejing2409&quot;,&quot;guest&quot;:true,&quot;org&quot;:&quot;BAAI&quot;},{&quot;user&quot;:&quot;graykingw&quot;,&quot;guest&quot;:true,&quot;org&quot;:&quot;BAAI&quot;},{&quot;user&quot;:&quot;daiteng01&quot;,&quot;guest&quot;:true,&quot;org&quot;:&quot;BAAI&quot;},{&quot;user&quot;:&quot;eyuansu71&quot;,&quot;guest&quot;:true,&quot;org&quot;:&quot;BAAI&quot;},{&quot;user&quot;:&quot;Lyfly2024&quot;,&quot;guest&quot;:true,&quot;org&quot;:&quot;BAAI&quot;},{&quot;user&quot;:&quot;xianbao&quot;,&quot;org&quot;:&quot;Huggingface&quot;},{&quot;user&quot;:&quot;clefourrier&quot;,&quot;org&quot;:&quot;Huggingface&quot;}],&quot;canonical&quot;:true,&quot;isUpvotedByUser&quot;:false,&quot;publishedAt&quot;:&quot;2024-11-20T00:00:00.000Z&quot;,&quot;slug&quot;:&quot;debate&quot;,&quot;title&quot;:&quot;Letting Large Models Debate: The First Multilingual LLM Debate Competition&quot;,&quot;upvotes&quot;:19,&quot;thumbnail&quot;:&quot;/blog/assets/leaderboards-on-the-hub/thumbnail_flageval.png&quot;,&quot;guest&quot;:true},&quot;blogUrl&quot;:&quot;/blog&quot;,&quot;lang&quot;:&quot;en&quot;,&quot;loggedInUser&quot;:&quot;fayadchowdhury&quot;}"><a class="flex lg:col-span-1 hover:shadow-alternate group relative flex-col overflow-hidden rounded-xl border border-gray-100 shadow-sm transition-shadow" href="/blog/debate"><div class="aspect-[1.91/1] w-full rounded-b shadow-alternate relative flex-none overflow-hidden rounded-lg bg-white"><div class="absolute inset-0 group-hover:opacity-40 dark:backdrop-brightness-105"></div>

		<img src="/blog/assets/leaderboards-on-the-hub/thumbnail_flageval.png" class="h-full w-full object-cover group-hover:brightness-110" alt=""></div>

	<div class="flex flex-col p-4"><h2 class="font-serif font-semibold group-hover:underline text-xl">Letting Large Models Debate: The First Multilingual LLM Debate Competition</h2>

		<p class="mt-3 flex flex-wrap items-center gap-y-1.5 font-mono text-xs text-gray-500">
				ByÂ <object title="">

<span class="inline-block "><span class="contents"><a href="/xuanricheng" class="hover:underline">xuanricheng</a></span>

	</span></object>
				<span class="mx-2 h-1 w-1 flex-none bg-gray-200"></span>
			<span>November 20, 2024</span>
			<span class="mx-2 h-1 w-1 flex-none bg-gray-200"></span>
				<span class="rounded bg-gray-100 px-1 text-gray-800 dark:bg-gray-800">guest</span>
			<span class="px-1.5 text-gray-300">â€¢</span>

				<svg class="flex-none w-3 mr-1 text-gray-400" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12" fill="transparent"><path d="M9.30013 9.29152H9.3H2.7H2.69987C2.62308 9.29154 2.54762 9.27146 2.481 9.23328C2.41437 9.1951 2.3589 9.14015 2.32009 9.07389C2.28128 9.00763 2.26048 8.93237 2.25977 8.85558C2.25907 8.7798 2.27796 8.70513 2.31458 8.63882L5.62238 2.9426L5.67518 2.85168C5.7059 2.81806 5.74178 2.78928 5.78164 2.76649C5.84813 2.72848 5.9234 2.70848 6 2.70848C6.0766 2.70848 6.15187 2.72848 6.21836 2.76649C6.28441 2.80425 6.33953 2.85848 6.37836 2.92389L9.68527 8.63855C9.72199 8.70493 9.74093 8.7797 9.74023 8.85558C9.73952 8.93237 9.71872 9.00763 9.67991 9.07389C9.6411 9.14015 9.58563 9.1951 9.519 9.23328C9.45238 9.27146 9.37692 9.29154 9.30013 9.29152Z" stroke="currentColor"></path></svg>

				19</p></div></a></div></div></div></div></div>

		<div class="w-56 flex-none pt-28 max-lg:hidden"><div class="SVELTE_HYDRATER contents" data-target="UpvoteControl" data-props="{&quot;authLight&quot;:{&quot;csrfToken&quot;:&quot;eyJkYXRhIjp7ImV4cGlyYXRpb24iOjE3MzMyNzA0Nzg2ODEsInVzZXJJZCI6IjY1NTQwMWJmNDMyYWYxYjExMTU3NDU4NSJ9LCJzaWduYXR1cmUiOiIzZmVhNDEwOGRlNmUwMWM5MjkwZDJiMDgyMDFmZGFlYTQzYmQ4ZTUxNjJiZGE1NmJkODQzNjgxZTRiZTE0NTExIn0=&quot;,&quot;hasHfLevelAccess&quot;:false,&quot;u&quot;:{&quot;avatarUrl&quot;:&quot;/avatars/60c9e476e92f24b4f1719e25c7563b73.svg&quot;,&quot;isPro&quot;:false,&quot;orgs&quot;:[],&quot;user&quot;:&quot;fayadchowdhury&quot;,&quot;canPost&quot;:false,&quot;canHaveBilling&quot;:true,&quot;canCreateOrg&quot;:true,&quot;theme&quot;:&quot;system&quot;,&quot;notifications&quot;:{},&quot;usage&quot;:{&quot;storage&quot;:{&quot;limit&quot;:500000000000,&quot;used&quot;:0,&quot;count&quot;:0},&quot;inferenceApi&quot;:{&quot;used&quot;:0,&quot;limit&quot;:1000,&quot;duration&quot;:86400,&quot;renewal&quot;:86400,&quot;lastUpdated&quot;:&quot;2024-12-03T00:00:55.093Z&quot;},&quot;zeroGpu&quot;:{&quot;base&quot;:300,&quot;current&quot;:300,&quot;lastUpdated&quot;:&quot;2024-12-03T00:00:55.093Z&quot;}}}},&quot;classNames&quot;:&quot;lg:max-w-60 lg:flex-col lg:!items-start&quot;,&quot;maxShown&quot;:12,&quot;apiUrlPrefix&quot;:&quot;/api/blog/introducing-csearch&quot;,&quot;postLoginRedirectUrl&quot;:&quot;/blog/introducing-csearch&quot;,&quot;style&quot;:&quot;horizontal&quot;,&quot;color&quot;:&quot;gray&quot;,&quot;upvotedColor&quot;:&quot;orange&quot;,&quot;upvoted&quot;:false,&quot;upvoters&quot;:[{&quot;_id&quot;:&quot;6032802e1f993496bc14d9e3&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/6032802e1f993496bc14d9e3/w6hr-DEQot4VVkoyRIBiy.png&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Omar Sanseviero&quot;,&quot;user&quot;:&quot;osanseviero&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;60638ffcc1b431dab68bf985&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1652289278612-60638ffcc1b431dab68bf985.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Rohola Zandie&quot;,&quot;user&quot;:&quot;Roh&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;60ff9a16d97410273ee4f3c4&quot;,&quot;avatarUrl&quot;:&quot;/avatars/15262cde59a2df265215575b8c97a867.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Manpreet Singh&quot;,&quot;user&quot;:&quot;singhmnprt01&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;618b40a1cabd3c4c8e448203&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/618b40a1cabd3c4c8e448203/Ccgv0dwgHEIb4vwYwHgQz.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Sambit Mukherjee&quot;,&quot;user&quot;:&quot;sadhaklal&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;62928e6556fedc76e3971e19&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/62928e6556fedc76e3971e19/Ye0xR859GTCs3ZTZSvlM3.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Ivan Sorokin&quot;,&quot;user&quot;:&quot;sorokin&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;62ff609559b9ff1ccb53228a&quot;,&quot;avatarUrl&quot;:&quot;/avatars/8e40cbf1a600b01e9b1ebc2f1704cb19.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Osama Khan&quot;,&quot;user&quot;:&quot;khanosama783&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;63ff00a512c51862e5d661d8&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/63ff00a512c51862e5d661d8/z4FmjxxEtEvvMTESqJv3L.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;yao&quot;,&quot;user&quot;:&quot;yaowenxu&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;64c3e7625e5bc55a92de44c7&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/urIJ05HhEJn0auwuA39c6.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Pedro Henrique Ton Pauletti&quot;,&quot;user&quot;:&quot;pedropauletti&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;64fdd75999123d7698d04d69&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/64fdd75999123d7698d04d69/1mfU8hchj-LShzzTtxAAK.jpeg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;Kimleang Ly&quot;,&quot;user&quot;:&quot;kimleang123&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;65f61c4f133b39d44f331d88&quot;,&quot;avatarUrl&quot;:&quot;/avatars/cbef8f9192d219949f6201ebd38fa7af.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;ayoub elmendoub&quot;,&quot;user&quot;:&quot;showgun01&quot;,&quot;type&quot;:&quot;user&quot;},{&quot;_id&quot;:&quot;665369e6420092799deb865f&quot;,&quot;avatarUrl&quot;:&quot;/avatars/284bd5458f559e1036a7c68cd5f1c8e2.svg&quot;,&quot;isPro&quot;:false,&quot;fullname&quot;:&quot;morror&quot;,&quot;user&quot;:&quot;hvgg1ngface&quot;,&quot;type&quot;:&quot;user&quot;}],&quot;upvotes&quot;:11}"><div class="flex flex-wrap items-center gap-2.5 pt-1 lg:max-w-60 lg:flex-col lg:!items-start"><label class="shadow-alternate group flex h-9 cursor-pointer select-none items-center gap-2 rounded-lg border pl-3 pr-3.5 border-gray-300 bg-white dark:bg-gray-850"><input  type="checkbox"  class="peer hidden">
		<svg class="text-xs text-gray-500 peer-checked:text-gray-500 group-hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path fill="currentColor" d="M5.19 2.67a.94.94 0 0 1 1.62 0l3.31 5.72a.94.94 0 0 1-.82 1.4H2.7a.94.94 0 0 1-.82-1.4l3.31-5.7v-.02Z"></path></svg>
		Upvote

		<div class="font-semibold text-orange-500">11</div></label>


	<ul class="flex items-center  flex-row  text-base   "><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="osanseviero" style="content-visibility:auto;"><a href="/osanseviero" title="osanseviero"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/6032802e1f993496bc14d9e3/w6hr-DEQot4VVkoyRIBiy.png">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="Roh" style="content-visibility:auto;"><a href="/Roh" title="Roh"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1652289278612-60638ffcc1b431dab68bf985.jpeg">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="singhmnprt01" style="content-visibility:auto;"><a href="/singhmnprt01" title="singhmnprt01"><img class="overflow-hidden rounded-full" alt="" src="/avatars/15262cde59a2df265215575b8c97a867.svg">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="sadhaklal" style="content-visibility:auto;"><a href="/sadhaklal" title="sadhaklal"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/618b40a1cabd3c4c8e448203/Ccgv0dwgHEIb4vwYwHgQz.jpeg">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="sorokin" style="content-visibility:auto;"><a href="/sorokin" title="sorokin"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/62928e6556fedc76e3971e19/Ye0xR859GTCs3ZTZSvlM3.jpeg">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="khanosama783" style="content-visibility:auto;"><a href="/khanosama783" title="khanosama783"><img class="overflow-hidden rounded-full" alt="" src="/avatars/8e40cbf1a600b01e9b1ebc2f1704cb19.svg">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="yaowenxu" style="content-visibility:auto;"><a href="/yaowenxu" title="yaowenxu"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/63ff00a512c51862e5d661d8/z4FmjxxEtEvvMTESqJv3L.jpeg">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="pedropauletti" style="content-visibility:auto;"><a href="/pedropauletti" title="pedropauletti"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/urIJ05HhEJn0auwuA39c6.jpeg">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="kimleang123" style="content-visibility:auto;"><a href="/kimleang123" title="kimleang123"><img class="overflow-hidden rounded-full" alt="" src="https://cdn-avatars.huggingface.co/v1/production/uploads/64fdd75999123d7698d04d69/1mfU8hchj-LShzzTtxAAK.jpeg">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="showgun01" style="content-visibility:auto;"><a href="/showgun01" title="showgun01"><img class="overflow-hidden rounded-full" alt="" src="/avatars/cbef8f9192d219949f6201ebd38fa7af.svg">
					</a>
			</li><li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   block flex-none rounded-full border-2 border-white bg-gradient-to-br from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="hvgg1ngface" style="content-visibility:auto;"><a href="/hvgg1ngface" title="hvgg1ngface"><img class="overflow-hidden rounded-full" alt="" src="/avatars/284bd5458f559e1036a7c68cd5f1c8e2.svg">
					</a>
			</li>

		<li class="text-gray-600 hover:text-gray-700 order-last ml-3"></li></ul></div>



</div></div></div></main>

	<footer class="b-12 mb-2 flex border-t border-gray-100 md:h-14"><nav class="container flex flex-col justify-between space-y-2 py-6 text-gray-500 md:flex-row md:items-center md:space-y-0 md:py-0 md:text-sm"><div class="font-semibold text-black md:hidden">Company</div>
		<div class="order-last pt-6 text-gray-400 md:order-none md:pt-0" href="Terms">Â© Hugging Face</div>
		<a class="hover:underline" href="/terms-of-service">TOS</a>
		<a class="hover:underline" href="/privacy">Privacy</a>
		<a class="hover:underline" href="/huggingface">About</a>
		<a class="hover:underline" href="https://apply.workable.com/huggingface/">Jobs</a>
		<a href="/" class="group order-first flex-none pb-6 md:order-none md:pb-0"><svg class="h-7 w-7 transition-transform group-hover:-translate-y-px" viewBox="0 0 95 88" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M47.2119 76.5C66.4037 76.5 81.9619 60.9419 81.9619 41.75C81.9619 22.5581 66.4037 7 47.2119 7C28.02 7 12.4619 22.5581 12.4619 41.75C12.4619 60.9419 28.02 76.5 47.2119 76.5Z" fill="#FFD21E"></path><path d="M81.9619 41.75C81.9619 22.5581 66.4037 7 47.2119 7C28.02 7 12.4619 22.5581 12.4619 41.75C12.4619 60.9419 28.02 76.5 47.2119 76.5C66.4037 76.5 81.9619 60.9419 81.9619 41.75ZM8.46185 41.75C8.46185 20.349 25.8108 3 47.2119 3C68.6129 3 85.9619 20.349 85.9619 41.75C85.9619 63.151 68.6129 80.5 47.2119 80.5C25.8108 80.5 8.46185 63.151 8.46185 41.75Z" fill="#FF9D0B"></path><path d="M58.5024 32.2915C59.7768 32.7415 60.2839 35.3615 61.5713 34.6769C64.0095 33.3805 64.9351 30.353 63.6387 27.9148C62.3423 25.4767 59.3148 24.5511 56.8766 25.8475C54.4384 27.1439 53.5128 30.1714 54.8092 32.6096C55.4211 33.7604 57.3632 31.8892 58.5024 32.2915Z" fill="#3A3B45"></path><path d="M34.9454 32.2915C33.671 32.7415 33.164 35.3615 31.8766 34.6769C29.4384 33.3805 28.5128 30.353 29.8092 27.9148C31.1056 25.4767 34.1331 24.5511 36.5713 25.8475C39.0095 27.1439 39.9351 30.1714 38.6387 32.6096C38.0268 33.7604 36.0846 31.8892 34.9454 32.2915Z" fill="#3A3B45"></path><path d="M46.9619 56.289C56.7903 56.289 59.9619 47.5261 59.9619 43.0262C59.9619 40.6875 58.3898 41.4236 55.8718 42.6702C53.5449 43.8222 50.4102 45.4101 46.9619 45.4101C39.7822 45.4101 33.9619 38.5263 33.9619 43.0262C33.9619 47.5261 37.1334 56.289 46.9619 56.289Z" fill="#3A3B45"></path><mask id="mask0" mask-type="alpha" maskUnits="userSpaceOnUse" x="33" y="41" width="27" height="16"><path d="M46.9619 56.289C56.7903 56.289 59.9619 47.5261 59.9619 43.0262C59.9619 40.6875 58.3898 41.4236 55.8718 42.6702C53.5449 43.8222 50.4102 45.4101 46.9619 45.4101C39.7822 45.4101 33.9619 38.5263 33.9619 43.0262C33.9619 47.5261 37.1334 56.289 46.9619 56.289Z" fill="white"></path></mask><g mask="url(#mask0)"><path d="M47.2119 66.5C52.0018 66.5 55.8848 62.617 55.8848 57.8271C55.8848 54.0962 53.5291 50.9156 50.224 49.6915C50.1023 49.6464 49.9794 49.604 49.8553 49.5643C49.0219 49.2979 48.1337 52.1623 47.2119 52.1623C46.3506 52.1623 45.5186 49.2797 44.7332 49.5135C41.151 50.5799 38.5389 53.8984 38.5389 57.8271C38.5389 62.617 42.4219 66.5 47.2119 66.5Z" fill="#F94040"></path></g><path d="M70.7119 37C72.5068 37 73.9619 35.5449 73.9619 33.75C73.9619 31.9551 72.5068 30.5 70.7119 30.5C68.9169 30.5 67.4619 31.9551 67.4619 33.75C67.4619 35.5449 68.9169 37 70.7119 37Z" fill="#FF9D0B"></path><path d="M24.2119 37C26.0068 37 27.4619 35.5449 27.4619 33.75C27.4619 31.9551 26.0068 30.5 24.2119 30.5C22.4169 30.5 20.9619 31.9551 20.9619 33.75C20.9619 35.5449 22.4169 37 24.2119 37Z" fill="#FF9D0B"></path><path class="origin-bottom-right transition-transform group-hover:-rotate-6" d="M17.5238 48C15.9048 48 14.4578 48.665 13.4488 49.871C12.8248 50.618 12.1728 51.822 12.1198 53.625C11.4408 53.43 10.7878 53.321 10.1778 53.321C8.6278 53.321 7.2278 53.915 6.2378 54.994C4.9658 56.379 4.4008 58.081 4.6468 59.784C4.7638 60.595 5.0348 61.322 5.4398 61.995C4.5858 62.686 3.9568 63.648 3.6528 64.805C3.4148 65.712 3.1708 67.601 4.4448 69.547C4.3638 69.674 4.2878 69.806 4.2168 69.941C3.4508 71.395 3.4018 73.038 4.0778 74.568C5.1028 76.887 7.6498 78.714 12.5958 80.675C15.6728 81.895 18.4878 82.675 18.5128 82.682C22.5808 83.737 26.2598 84.273 29.4448 84.273C35.2988 84.273 39.4898 82.48 41.9018 78.944C45.7838 73.25 45.2288 68.042 40.2058 63.022C37.4258 60.244 35.5778 56.148 35.1928 55.249C34.4168 52.587 32.3648 49.628 28.9538 49.628H28.9528C28.6658 49.628 28.3758 49.651 28.0898 49.696C26.5958 49.931 25.2898 50.791 24.3568 52.085C23.3498 50.833 22.3718 49.837 21.4868 49.275C20.1528 48.429 18.8198 48 17.5238 48ZM17.5238 52C18.0338 52 18.6568 52.217 19.3438 52.653C21.4768 54.006 25.5928 61.081 27.0998 63.833C27.6048 64.755 28.4678 65.145 29.2448 65.145C30.7868 65.145 31.9908 63.612 29.3858 61.664C25.4688 58.733 26.8428 53.942 28.7128 53.647C28.7948 53.634 28.8758 53.628 28.9538 53.628C30.6538 53.628 31.4038 56.558 31.4038 56.558C31.4038 56.558 33.6018 62.078 37.3778 65.851C41.1538 69.625 41.3488 72.654 38.5968 76.69C36.7198 79.442 33.1268 80.273 29.4448 80.273C25.6258 80.273 21.7108 79.379 19.5168 78.81C19.4088 78.782 6.0658 75.013 7.7558 71.805C8.0398 71.266 8.5078 71.05 9.0968 71.05C11.4768 71.05 15.8058 74.592 17.6668 74.592C18.0828 74.592 18.3758 74.415 18.4958 73.983C19.2888 71.138 6.4388 69.942 7.5218 65.821C7.7128 65.092 8.2308 64.796 8.9588 64.797C12.1038 64.797 19.1598 70.328 20.6388 70.328C20.7518 70.328 20.8328 70.295 20.8768 70.225C21.6178 69.029 21.2118 68.194 15.9888 65.033C10.7658 61.871 7.0998 59.969 9.1848 57.699C9.4248 57.437 9.7648 57.321 10.1778 57.321C13.3488 57.322 20.8408 64.14 20.8408 64.14C20.8408 64.14 22.8628 66.243 24.0858 66.243C24.3668 66.243 24.6058 66.132 24.7678 65.858C25.6348 64.396 16.7148 57.636 16.2118 54.847C15.8708 52.957 16.4508 52 17.5238 52Z" fill="#FF9D0B"></path><path class="origin-bottom-right transition-transform group-hover:-rotate-6" d="M38.5967 76.6898C41.3487 72.6538 41.1537 69.6248 37.3777 65.8508C33.6017 62.0778 31.4037 56.5578 31.4037 56.5578C31.4037 56.5578 30.5827 53.3518 28.7127 53.6468C26.8427 53.9418 25.4697 58.7328 29.3867 61.6638C33.3037 64.5938 28.6067 66.5848 27.0997 63.8328C25.5927 61.0808 21.4777 54.0058 19.3437 52.6528C17.2107 51.2998 15.7087 52.0578 16.2117 54.8468C16.7147 57.6358 25.6357 64.3958 24.7677 65.8588C23.8997 67.3208 20.8407 64.1398 20.8407 64.1398C20.8407 64.1398 11.2687 55.4288 9.18465 57.6988C7.10065 59.9688 10.7657 61.8708 15.9887 65.0328C21.2127 68.1938 21.6177 69.0288 20.8767 70.2248C20.1347 71.4208 8.60465 61.6998 7.52165 65.8208C6.43965 69.9418 19.2887 71.1378 18.4957 73.9828C17.7027 76.8288 9.44465 68.5978 7.75565 71.8048C6.06565 75.0128 19.4087 78.7818 19.5167 78.8098C23.8267 79.9278 34.7727 82.2968 38.5967 76.6898Z" fill="#FFD21E"></path><path class="origin-bottom-left transition-transform group-hover:rotate-6" d="M77.3999 48C79.0189 48 80.4659 48.665 81.4749 49.871C82.0989 50.618 82.7509 51.822 82.8039 53.625C83.4829 53.43 84.1359 53.321 84.7459 53.321C86.2959 53.321 87.6959 53.915 88.6859 54.994C89.9579 56.379 90.5229 58.081 90.2769 59.784C90.1599 60.595 89.8889 61.322 89.4839 61.995C90.3379 62.686 90.9669 63.648 91.2709 64.805C91.5089 65.712 91.7529 67.601 90.4789 69.547C90.5599 69.674 90.6359 69.806 90.7069 69.941C91.4729 71.395 91.5219 73.038 90.8459 74.568C89.8209 76.887 87.2739 78.714 82.3279 80.675C79.2509 81.895 76.4359 82.675 76.4109 82.682C72.3429 83.737 68.6639 84.273 65.4789 84.273C59.6249 84.273 55.4339 82.48 53.0219 78.944C49.1399 73.25 49.6949 68.042 54.7179 63.022C57.4979 60.244 59.3459 56.148 59.7309 55.249C60.5069 52.587 62.5589 49.628 65.9699 49.628H65.9709C66.2579 49.628 66.5479 49.651 66.8339 49.696C68.3279 49.931 69.6339 50.791 70.5669 52.085C71.5739 50.833 72.5519 49.837 73.4369 49.275C74.7709 48.429 76.1039 48 77.3999 48ZM77.3999 52C76.8899 52 76.2669 52.217 75.5799 52.653C73.4469 54.006 69.3309 61.081 67.8239 63.833C67.3189 64.755 66.4559 65.145 65.6789 65.145C64.1369 65.145 62.9329 63.612 65.5379 61.664C69.4549 58.733 68.0809 53.942 66.2109 53.647C66.1289 53.634 66.0479 53.628 65.9699 53.628C64.2699 53.628 63.5199 56.558 63.5199 56.558C63.5199 56.558 61.3219 62.078 57.5459 65.851C53.7699 69.625 53.5749 72.654 56.3269 76.69C58.2039 79.442 61.7969 80.273 65.4789 80.273C69.2979 80.273 73.2129 79.379 75.4069 78.81C75.5149 78.782 88.8579 75.013 87.1679 71.805C86.8839 71.266 86.4159 71.05 85.8269 71.05C83.4469 71.05 79.1179 74.592 77.2569 74.592C76.8409 74.592 76.5479 74.415 76.4279 73.983C75.6349 71.138 88.4849 69.942 87.4019 65.821C87.2109 65.092 86.6929 64.796 85.9649 64.797C82.8199 64.797 75.7639 70.328 74.2849 70.328C74.1719 70.328 74.0909 70.295 74.0469 70.225C73.3059 69.029 73.7119 68.194 78.9349 65.033C84.1579 61.871 87.8239 59.969 85.7389 57.699C85.4989 57.437 85.1589 57.321 84.7459 57.321C81.5749 57.322 74.0829 64.14 74.0829 64.14C74.0829 64.14 72.0609 66.243 70.8379 66.243C70.5569 66.243 70.3179 66.132 70.1559 65.858C69.2889 64.396 78.2089 57.636 78.7119 54.847C79.0529 52.957 78.4729 52 77.3999 52Z" fill="#FF9D0B"></path><path class="origin-bottom-left transition-transform group-hover:rotate-6" d="M56.3271 76.6898C53.5751 72.6538 53.7701 69.6248 57.5461 65.8508C61.3221 62.0778 63.5201 56.5578 63.5201 56.5578C63.5201 56.5578 64.3411 53.3518 66.2111 53.6468C68.0811 53.9418 69.4541 58.7328 65.5371 61.6638C61.6201 64.5938 66.3171 66.5848 67.8241 63.8328C69.3311 61.0808 73.4461 54.0058 75.5801 52.6528C77.7131 51.2998 79.2151 52.0578 78.7121 54.8468C78.2091 57.6358 69.2881 64.3958 70.1561 65.8588C71.0241 67.3208 74.0831 64.1398 74.0831 64.1398C74.0831 64.1398 83.6551 55.4288 85.7391 57.6988C87.8231 59.9688 84.1581 61.8708 78.9351 65.0328C73.7111 68.1938 73.3061 69.0288 74.0471 70.2248C74.7891 71.4208 86.3191 61.6998 87.4021 65.8208C88.4841 69.9418 75.6351 71.1378 76.4281 73.9828C77.2211 76.8288 85.4791 68.5978 87.1681 71.8048C88.8581 75.0128 75.5151 78.7818 75.4071 78.8098C71.0971 79.9278 60.1511 82.2968 56.3271 76.6898Z" fill="#FFD21E"></path></svg></a>
		<div class="pt-6 font-semibold text-black md:hidden md:pt-0">Website</div>

		<a class="hover:underline" href="/models">Models</a>
		<a class="hover:underline" href="/datasets">Datasets</a>
		<a class="hover:underline" href="/spaces">Spaces</a>
		<a class="hover:underline" href="/pricing">Pricing</a>
		<a class="hover:underline" href="/docs">Docs</a></nav></footer></div>

		<script>
			import("\/front\/build\/kube-8e721ee\/index.js");
			window.moonSha = "kube-8e721ee\/";
			window.__hf_deferred = {};
		</script>

		<!-- Stripe -->
		<script>
			if (["hf.co", "huggingface.co"].includes(window.location.hostname)) {
				const script = document.createElement("script");
				script.src = "https://js.stripe.com/v3/";
				script.async = true;
				document.head.appendChild(script);
			}
		</script>
	</body>
</html>
